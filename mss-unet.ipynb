{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install einops pytorch_lightning diffusers==0.12.1 kornia librosa accelerate torchvision pandas==1.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src import *\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 8)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import SpectrogramDataset\n",
    "\n",
    "train_ds=SpectrogramDataset(target_dir='datasets/randomMIDI/PianoViolin11025/WAV/train/ins3',\n",
    "                            condition_dir='datasets/randomMIDI/PianoViolin11025/WAV/train/mix',\n",
    "                            return_pair=True,\n",
    "                            out_channels=1,\n",
    "                            return_mask=True\n",
    "                     )\n",
    "\n",
    "\n",
    "valid_ds=SpectrogramDataset(target_dir='datasets/randomMIDI/PianoViolin11025/WAV/val/ins3',\n",
    "                          condition_dir='datasets/randomMIDI/PianoViolin11025/WAV/val/mix',\n",
    "                          return_pair=True,\n",
    "                          out_channels=1,\n",
    "                          return_mask=True\n",
    "                     )\n",
    "\n",
    "test_ds=SpectrogramDataset(target_dir='datasets/randomMIDI/PianoViolin11025/WAV/test/ins3',\n",
    "                           condition_dir='datasets/randomMIDI/PianoViolin11025/WAV/test/mix',\n",
    "                           return_pair=True,\n",
    "                           out_channels=1,\n",
    "                           return_mask=True\n",
    "                     )\n",
    "\n",
    "img1,img2=train_ds[0]\n",
    "print(img1.shape)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img1.permute(1,2,0))\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(img2.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class plUnet(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 train_dataset,\n",
    "                 valid_dataset,\n",
    "                 batch_size,\n",
    "                 lr=1e-4,\n",
    "                 warm_up_steps=10000,\n",
    "                 loss_fn=torch.nn.functional.l1_loss):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.train_dataset=train_dataset\n",
    "        self.valid_dataset=valid_dataset\n",
    "        self.batch_size=batch_size\n",
    "        self.lr=lr\n",
    "        self.warm_up_steps= warm_up_steps\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "        channels, h, w = train_dataset[0][0].shape\n",
    "\n",
    "        self.model=UnetConvNextBlock(dim=64,\n",
    "                                     dim_mults = (1,2,4,8),\n",
    "                                     channels=channels,\n",
    "                                     out_dim=channels,\n",
    "                                     with_time_emb=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.output_T(self.model(self.input_T(x)))\n",
    "    \n",
    "    def input_T(self, input):\n",
    "        # By default, let the model accept samples in [0,1] range, and transform them automatically\n",
    "        return (input.clip(0,1).mul_(2)).sub_(1)\n",
    "    \n",
    "    def output_T(self, input):\n",
    "        # Inverse transform of model output from [-1,1] to [0,1] range\n",
    "        return (input.add_(1)).div_(2)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        mix, source = batch\n",
    "        model_output=self.model(self.input_T(mix))\n",
    "\n",
    "        loss = self.loss_fn(model_output, self.input_T(source))\n",
    "        \n",
    "        self.log('train_loss',loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        mix, source = batch\n",
    "        model_output=self.model(self.input_T(mix))\n",
    "\n",
    "        loss = self.loss_fn(model_output, self.input_T(source))\n",
    "        \n",
    "        self.log('train_loss',loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset,\n",
    "                          batch_size=self.batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        if self.valid_dataset is not None:\n",
    "            return DataLoader(self.valid_dataset,\n",
    "                              batch_size=self.batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=4)\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return  torch.optim.AdamW(list(filter(lambda p: p.requires_grad, self.model.parameters())), lr=self.lr)\n",
    "    \n",
    "    def optimizer_step(self, epoch, \n",
    "                       batch_idx, \n",
    "                       optimizer,\n",
    "                       optimizer_closure):\n",
    "        \n",
    "        # Linear Warm-up\n",
    "        if self.trainer.global_step < self.warm_up_steps:\n",
    "            lr_scale = min(1.0, float(self.trainer.global_step + 1) / self.warm_up_steps)\n",
    "            for pg in optimizer.param_groups:\n",
    "                pg[\"lr\"] = lr_scale * self.lr\n",
    "\n",
    "        optimizer.step(closure=optimizer_closure)\n",
    "\n",
    "        self.log('lr', pg['lr'], prog_bar=True)\n",
    "\n",
    "        return super().optimizer_step(epoch, batch_idx, optimizer, optimizer_closure)\n",
    "    \n",
    "model = plUnet(train_dataset=train_ds,\n",
    "               valid_dataset=valid_ds,\n",
    "               batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    default_root_dir=\"trained_models/unet/\",\n",
    "    max_epochs=2000,\n",
    "    callbacks=[EMA(0.9999)],\n",
    "    accelerator='auto'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
