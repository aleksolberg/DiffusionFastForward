{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install einops pytorch_lightning diffusers==0.12.1 kornia librosa accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src import *\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (8, 8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import SpectrogramDataset\n",
    "\n",
    "train_ds=SpectrogramDataset(target_dir='datasets/randomMIDI/PianoViolin11025/WAV/train/ins3',\n",
    "                            condition_dir='datasets/randomMIDI/PianoViolin11025/WAV/train/mix',\n",
    "                            return_pair=True,\n",
    "                            out_channels=1\n",
    "                     )\n",
    "\n",
    "\n",
    "valid_ds=SpectrogramDataset(target_dir='datasets/randomMIDI/PianoViolin11025/WAV/val/ins3',\n",
    "                          condition_dir='datasets/randomMIDI/PianoViolin11025/WAV/val/mix',\n",
    "                          return_pair=True,\n",
    "                          out_channels=1\n",
    "                     )\n",
    "\n",
    "test_ds=SpectrogramDataset(target_dir='datasets/randomMIDI/PianoViolin11025/WAV/test/ins3',\n",
    "                           condition_dir='datasets/randomMIDI/PianoViolin11025/WAV/test/mix',\n",
    "                           return_pair=True,\n",
    "                           out_channels=1\n",
    "                     )\n",
    "\n",
    "img1,img2=train_ds[0]\n",
    "print(img1.shape)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img1.permute(1,2,0))\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(img2.permute(1,2,0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = AutoencoderKL(in_channels=1,\n",
    "                            out_channels=1,\n",
    "                            down_block_types=(\"DownEncoderBlock2D\", \"DownEncoderBlock2D\", \"DownEncoderBlock2D\", \"DownEncoderBlock2D\"),\n",
    "                            up_block_types=(\"UpDecoderBlock2D\", \"UpDecoderBlock2D\", \"UpDecoderBlock2D\", \"UpDecoderBlock2D\"),\n",
    "                            block_out_channels=(128,256,512,512),\n",
    "                            layers_per_block=2,\n",
    "                            sample_size=256\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LatentDiffusionConditional(train_ds,\n",
    "                                 autoencoder,\n",
    "                                 valid_dataset=valid_ds,\n",
    "                                 lr=1e-5,\n",
    "                                 batch_size=2,\n",
    "                                 schedule='linear')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_steps=1,\n",
    "    callbacks=[EMA(0.9999)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.load('lightning_logs/version_6/checkpoints/epoch=1177-step=37725.ckpt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img1.permute(1,2,0))\n",
    "plt.title('Input')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(model.ae(img1.unsqueeze(0))[0].detach().cpu().permute(1,2,0))\n",
    "plt.title('AutoEncoder Reconstruction')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input,output=test_ds[0]\n",
    "batch_input=torch.stack(4*[input],0)\n",
    "\n",
    "#model.cuda()\n",
    "out=model(batch_input, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2+len(out),1)\n",
    "plt.imshow(input.permute(1,2,0))\n",
    "plt.title('Input')\n",
    "plt.axis('off')\n",
    "for idx in range(out.shape[0]):\n",
    "    plt.subplot(1,2+len(out),idx+2)\n",
    "    plt.imshow(out[idx].detach().cpu().permute(1,2,0))\n",
    "    plt.axis('off')\n",
    "plt.subplot(1,2+len(out),2+len(out))\n",
    "plt.imshow(output.permute(1,2,0))\n",
    "plt.title('Ground Truth')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = test_ds.get_phase(0)\n",
    "print(phase.shape)\n",
    "print(out[0].shape)\n",
    "name = test_ds.files[0]\n",
    "test_ds.save_audio(out[0], phase, name = name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
